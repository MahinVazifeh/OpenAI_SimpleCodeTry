* `OpenAI_Simplecode_for_Recepie.ipynb`: a minimal “LLM recipe” showing how to call a chat model with system/user messages (using the OpenAI-compatible SDK; can point to OpenAI or a local llama.cpp server).
* `Topwines.ipynb`: an end-to-end wine recommender using **Sentence Transformers** for embeddings + **Qdrant** for vector search, then passing the top matches into an LLM to generate a friendly recommendation.
* Setup steps (Python env, installs, protobuf pin), switching between OpenAI cloud and a local OpenAI-compatible server, and a simple RAG flow code sketch.

